{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce911c28-fa10-4911-a35e-2761447b97f5",
   "metadata": {},
   "source": [
    "# Estimate Gaussian Graphical Models using adaptive model average procedure\n",
    "For more details, see: https://skggm.github.io/skggm/tour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f2202-9ea2-415c-9805-31296e877403",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc637e3-f121-45d5-898f-ad7de817ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_covariance import (\n",
    "    QuicGraphicalLasso,\n",
    "    QuicGraphicalLassoCV,\n",
    "    QuicGraphicalLassoEBIC,\n",
    "    AdaptiveGraphicalLasso,\n",
    "    ModelAverage,\n",
    ")\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import tabulate\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_sparse_spd_matrix\n",
    "from sklearn.covariance import GraphicalLassoCV, ledoit_wolf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "import ast\n",
    "import os.path as op\n",
    "import pickle\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.utils import resample\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae75bdd-a73a-40a8-a190-371ceaf1cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_model_average_sklearn(X, method, penalization='random', n_trials=100, metric='log_likelihood', support_thresh=0.5, cv=10, lam=None, alphas=np.logspace(-5, 1, num=20)):\n",
    "    \"\"\"Run ModelAverage in default mode (QuicGraphicalLassoCV) to obtain proportion\n",
    "    matrix.\n",
    "\n",
    "    NOTE:  Only method = 'binary' really makes sense in this case.\n",
    "    \"\"\"\n",
    "    n_trials = n_trials\n",
    "\n",
    "    # if penalization is random, first find a decent scalar lam_ to build\n",
    "    # random perturbation matrix around. lam doesn't matter for fully-random.\n",
    "    if lam is None:\n",
    "        cv_model = GraphicalLassoCV(\n",
    "            alphas=alphas,\n",
    "            cv=cv\n",
    "        )\n",
    "        cv_model.fit(X)\n",
    "        lam = cv_model.alpha_\n",
    "        print(\"   lam: {}\".format(lam))\n",
    "    else:\n",
    "        lam = lam\n",
    "        \n",
    "    model = AdaptiveGraphicalLasso(\n",
    "        estimator=ModelAverage(\n",
    "            n_trials=n_trials, penalization=penalization, lam=lam, n_jobs=10, support_thresh=support_thresh,\n",
    "        ),\n",
    "        method=method,\n",
    "    )\n",
    "    model.fit(X)\n",
    "    lam_norm_ = np.linalg.norm(model.estimator_.lam_)\n",
    "    return model.estimator_.covariance_, model.estimator_.precision_, lam_norm_, model.estimator\n",
    "\n",
    "\n",
    "def learn_graph_structure_adaptive_average_sklearn(df, n_trials=100, penalization='random',score_metric=\"log_likelihood\", cv=10, lam=None,threshold=0.5, alphas=np.logspace(-5, 1, num=20)):\n",
    "    \n",
    "    # standardize the time series: using correlations rather than covariance\n",
    "    # former is more efficient for structure recovery\n",
    "    X = df.to_numpy()\n",
    "    X -= X.mean(axis=0)\n",
    "    X /= X.std(axis=0)\n",
    "\n",
    "    cov_adaptive, prec_adaptive, lam_adaptive, estimator = adaptive_model_average_sklearn(\n",
    "        X, \n",
    "        penalization='random',\n",
    "        method='binary', \n",
    "        n_trials=n_trials, \n",
    "        metric=score_metric,\n",
    "        support_thresh=threshold,\n",
    "        cv=cv,\n",
    "        lam=lam,\n",
    "        alphas=alphas,\n",
    "    )\n",
    "    \n",
    "    covariance_matrix_df = pd.DataFrame(cov_adaptive, columns = df.columns, index = df.columns)\n",
    "    precision_matrix_df = pd.DataFrame(prec_adaptive, columns = df.columns, index = df.columns)\n",
    "    support_matrix_df = pd.DataFrame(estimator.support_, columns = df.columns, index = df.columns)\n",
    "    proportion_matrix_df = pd.DataFrame(estimator.proportion_, columns = df.columns, index = df.columns)\n",
    "    \n",
    "    print(f\"Adaptive lam: {lam_adaptive}\")\n",
    "    \n",
    "    return covariance_matrix_df, precision_matrix_df, support_matrix_df, proportion_matrix_df, estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a459a6df-d60c-4c17-8ab5-dff0bd07b7a9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214db66f-ff74-4e60-98f6-f4e7c0f36da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = train | test\n",
    "dataset = 'train'\n",
    "test = False if dataset == 'train' else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c416a-064b-47cc-ba8e-d5c716dd10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_data_df = pd.read_pickle(f\"data/models_pickles_new/ern_crn_models_train_id_clean.pkl\")\n",
    "ern_cov_fal_data_df = pd.read_pickle(f\"data/models_pickles_new/ern_crn_cov_fal_models_train_id_clean.pkl\")\n",
    "\n",
    "datasets = [\n",
    "    ern_data_df, \n",
    "    ern_cov_fal_data_df, \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416a1b8-50da-48de-b1a8-f777c7a7b326",
   "metadata": {},
   "source": [
    "### Read consistency measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a46570-bb85-4c54-90ea-f2ef3c30016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "within_consistency_ern_df = pd.read_csv(f'data/consistency/{dataset}/ern_amplitude_within.csv')\n",
    "internal_consistency_ern_df = pd.read_csv(f'data/consistency/{dataset}/ern_amplitude_consistency.csv')\n",
    "within_consistency_crn_df = pd.read_csv(f'data/consistency/{dataset}/crn_amplitude_within.csv')\n",
    "internal_consistency_crn_df = pd.read_csv(f'data/consistency/{dataset}/crn_amplitude_consistency.csv')\n",
    "\n",
    "\n",
    "consistency_ern_df = within_consistency_ern_df.merge(internal_consistency_ern_df, on ='Unnamed: 0')\n",
    "consistency_ern_df = consistency_ern_df[consistency_ern_df['pipeline_x'] == 'Fz']\n",
    "\n",
    "consistency_crn_df = within_consistency_crn_df.merge(internal_consistency_crn_df, on ='Unnamed: 0')\n",
    "consistency_crn_df = consistency_crn_df[consistency_crn_df['pipeline_x'] == 'Fz']\n",
    "\n",
    "consistency_df = consistency_ern_df.merge(consistency_crn_df, on='id', suffixes=('_ern', '_crn'))\n",
    "consistency_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ee3d6-614e-4dba-bcaa-9961e285a384",
   "metadata": {},
   "source": [
    "### Filter participants on consistency measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee858f-9381-42dd-bb39-5c882196a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_consistency = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9255d49-ffff-48f3-b061-41e467870629",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_consistency = 0.6\n",
    "\n",
    "if exclude_consistency:\n",
    "    for i in range(0, len(datasets)):\n",
    "        datasets[i] = datasets[i].merge(consistency_df[['internal_variance_ern', 'internal_variance_crn', 'id']], on='id')\n",
    "        datasets[i] = datasets[i][\n",
    "            (datasets[i]['internal_variance_ern'] > threshold_consistency) &\n",
    "            (datasets[i]['internal_variance_crn'] > threshold_consistency)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db67a52-9395-4490-8a7f-3b271fb19c27",
   "metadata": {},
   "source": [
    "## Run Adaptive Model Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52209c1f-de72-476c-ac2c-23cb79c16883",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b59f206-c722-42ee-aae4-71fade70e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metric=\"log_likelihood\"\n",
    "n_trials = 10000\n",
    "alphas = np.linspace(0.01, 0.1, 20)\n",
    "cv = 3\n",
    "threshold = 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f80f5-10a0-4bf2-90db-fdffc847ad6b",
   "metadata": {},
   "source": [
    "#### ERN and CRN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415aaf06-b242-4e1f-a576-9e7ae35a0e71",
   "metadata": {},
   "source": [
    "Prepare datasets: remove skewed Washing and Neutralizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac872bb3-c93d-4ee2-a628-ed0b10752272",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cov_datasets = [\n",
    "    datasets[0], \n",
    "]\n",
    "\n",
    "columns_to_drop = ['WASH', 'NEU', 'id', 'internal_variance_ern', 'internal_variance_crn'] if exclude_consistency else ['WASH', 'NEU']\n",
    "\n",
    "datasets_no_skewed_scales = []\n",
    "for model in no_cov_datasets:\n",
    "    this_dataset = model.drop(columns=columns_to_drop)\n",
    "    datasets_no_skewed_scales.append(this_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c302970-68dd-4353-9899-57d38b373b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_matrixes = []\n",
    "covariance_matrixes = []\n",
    "support_matrixes = []\n",
    "proportion_matrixes = []\n",
    "average_estimators = []\n",
    "\n",
    "for model in datasets_no_skewed_scales:\n",
    "    covariance_matrix_df, precision_matrix_df, support_matrix_df, proportion_matrix_df, estimator  = learn_graph_structure_adaptive_average_sklearn(\n",
    "        model, \n",
    "        penalization='random',\n",
    "        n_trials=n_trials,\n",
    "        score_metric=score_metric,\n",
    "        cv=cv,\n",
    "        lam=None,\n",
    "        alphas=alphas,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "    precision_matrixes.append(precision_matrix_df)\n",
    "    covariance_matrixes.append(covariance_matrix_df)\n",
    "    support_matrixes.append(support_matrix_df)\n",
    "    proportion_matrixes.append(proportion_matrix_df)\n",
    "    average_estimators.append(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fab1f0-efc1-4a50-8af0-39dbef56b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_matrixes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b81d3f-f52d-4b96-ab1f-86266f6fe845",
   "metadata": {},
   "source": [
    "Save  the precision and covariance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ddb77-091c-4d9f-98c0-bcff2feb4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, precision_matrix in enumerate(precision_matrixes):\n",
    "    precision_matrix.to_pickle(f\"new_data/precision_matrixes/{dataset}/precision_matrix_{index}_ntrials_{n_trials}_sklearn_cv{cv}_th{str(threshold)}_without_skewd_ern_crn.pkl\")\n",
    "\n",
    "for index, covariance_matrix in enumerate(covariance_matrixes):\n",
    "    covariance_matrix.to_pickle(f\"new_data/covariance_matrixes/{dataset}/covariance_matrix_{index}_ntrials_{n_trials}_sklearn_cv{cv}_th{str(threshold)}_without_skewd_ern_crn.pkl\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb35bd-fcd7-40fe-8554-e8648e9d1337",
   "metadata": {},
   "source": [
    "Save the support and proportion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241d212-1cc3-441d-80e2-7de0a2bafbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, support_matrix in enumerate(support_matrixes):\n",
    "    support_matrix.to_pickle(f\"new_data/support_proportion/{dataset}/support_matrix_{index}_ntrials_{n_trials}_sklearn_cv{cv}_th{str(threshold)}_without_skewd_ern_crn.pkl\")\n",
    "\n",
    "for index, proportion_matrix in enumerate(proportion_matrixes):\n",
    "    proportion_matrix.to_pickle(f\"new_data/support_proportion/{dataset}/proportion_matrix_{index}_ntrials_{n_trials}_sklearn_cv{cv}_th{str(threshold)}_without_skewd_ern_crn.pkl\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65feeb8d-151a-4efd-b80e-9d0bb320da44",
   "metadata": {},
   "source": [
    "Save the estimators from N trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5d2e9-da33-434e-a1fe-d2bd3533630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, average_estimator in enumerate(average_estimators):\n",
    "    estimators_df = pd.DataFrame({\"estimators\": average_estimator.estimators_})\n",
    "    estimators_df.to_pickle(f\"new_data/n_estimators/{dataset}/stability_selection_estimators_{index+1}_ntrials_{n_trials}_sklearn_cv{cv}_th{str(threshold)}_without_skewd_ern_crn.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1388f7-64bb-4b6a-b6e9-c6eb335ba08c",
   "metadata": {},
   "source": [
    "#### ERN with covariates and CRN with covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e9480-5866-4a1a-aeb7-633c27400936",
   "metadata": {},
   "source": [
    "Prepare datasets: remove skewed Washing and Neutralizing, and remove gender from the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e2d5c-2383-4a52-b2f5-3766c98cbc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cov_datasets = [\n",
    "    datasets[1], \n",
    "]\n",
    "\n",
    "columns_to_drop = ['WASH', 'NEU', 'Sex', 'id', 'internal_variance_ern', 'internal_variance_crn'] if exclude_consistency else ['WASH', 'NEU','Sex']\n",
    "\n",
    "datasets_no_skewed_scales = []\n",
    "for model in no_cov_datasets:\n",
    "    this_dataset = model.drop(columns=columns_to_drop)\n",
    "    datasets_no_skewed_scales.append(this_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23340a09-2ff3-461b-a443-8ce794f51452",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_matrixes = []\n",
    "covariance_matrixes = []\n",
    "support_matrixes = []\n",
    "proportion_matrixes = []\n",
    "average_estimators = []\n",
    "\n",
    "for model in datasets_no_skewed_scales:\n",
    "    covariance_matrix_df, precision_matrix_df, support_matrix_df, proportion_matrix_df, estimator = learn_graph_structure_adaptive_average_sklearn(\n",
    "        model, \n",
    "        penalization='random',\n",
    "        n_trials=n_trials,\n",
    "        score_metric=score_metric,\n",
    "        cv=cv,\n",
    "        lam=None,\n",
    "        alphas=alphas,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "    precision_matrixes.append(precision_matrix_df)\n",
    "    covariance_matrixes.append(covariance_matrix_df)\n",
    "    support_matrixes.append(support_matrix_df)\n",
    "    proportion_matrixes.append(proportion_matrix_df)\n",
    "    average_estimators.append(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3fc3f-43d2-4f88-b187-d6c45f64f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_matrixes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039efc9-fe2c-4d39-bea1-39556bdd3f33",
   "metadata": {},
   "source": [
    "Save the precision and covariance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f73e0-4867-4217-bf97-af0d1f550044",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, precision_matrix in enumerate(precision_matrixes):\n",
    "    precision_matrix.to_pickle(f\"new_data/precision_matrixes/{dataset}/precision_matrix_{index}_ntrials_{n_trials}_sklearn_cv{cv}_th{str(threshold)}_without_skewd_no_sex_cov_ern_crn.pkl\")\n",
    "\n",
    "for index, covariance_matrix in enumerate(covariance_matrixes):\n",
    "    covariance_matrix.to_pickle(f\"new_data/covariance_matrixes/{dataset}/covariance_matrix_{index}_ntrials_{n_trials}_sklearn_cv{cv}_th{str(threshold)}_without_skewed_no_sex_cov_ern_crn.pkl\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc54b1-370e-4ff6-a028-8f3fca8d647c",
   "metadata": {},
   "source": [
    "Save the support and proportion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1fcb35-7041-4abf-92c7-b7331e61e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, support_matrix in enumerate(support_matrixes):\n",
    "    support_matrix.to_pickle(f\"new_data/support_proportion/{dataset}/support_matrix_{index}_ntrials_{n_trials}_sklearn_cv{cv}_th{str(threshold)}_without_skewd_no_sex_cov_ern_crn.pkl\")\n",
    "\n",
    "for index, proportion_matrix in enumerate(proportion_matrixes):\n",
    "    proportion_matrix.to_pickle(f\"new_data/support_proportion/{dataset}/proportion_matrix_{index}_ntrials_{n_trials}_sklearn_cv{cv}_th{str(threshold)}_without_skewed_no_sex_cov_ern_crn.pkl\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2912264e-6c4d-44f3-ab8a-32a4eac77aa7",
   "metadata": {},
   "source": [
    "Save the estimators from N trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd189c93-3ea2-47ba-b5b3-ee72abe3bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, average_estimator in enumerate(average_estimators):\n",
    "    estimators_df = pd.DataFrame({\"estimators\": average_estimator.estimators_})\n",
    "    estimators_df.to_pickle(f\"new_data/n_estimators/{dataset}/stability_selection_estimators_{index+1}_ntrials_{n_trials}_sklearn_cv{cv}_th{str(threshold)}_without_skewd_no_sex_cov_ern_crn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b96c52-49b9-43ac-b2f5-d1779cdfd3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skggmtest",
   "language": "python",
   "name": "skggmtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
